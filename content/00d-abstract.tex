\addchap*{Abstract}
\markboth{Abstract}{}

Consider an agent that can cooperate with others and autonomously negotiate, to reach an agreement. These agents could achieve great results, such as increasing the profitability of a factory. This type of agent is practical in complex and realistic environments (e.g. supply chain management). In the experiments of this thesis, it is proposed to use some creative methods to implement learnable agents to achieve these goals. When interacting with others continuously, the agent’s strategy will be improved. The learned strategy enables autonomous agents to negotiate in real time with multiple different types of unknown opponents on complex and multiple issues. In the last decades, a lot of work tried to develop negotiation agency by simplifying the negotiation environment or with the help of expert knowledges. In recent years, many interesting end-to-end multi-agent deep reinforcement learning methods are proposed and successfully applied in complex environments, such as Dota 2, Starcraft. Hence, some questions will naturally be raised: How to use these new methods and how about the results without simplifying the environments and without the help of extra knowledges? The work of this thesis attempts to establish training environments and implement end-to-end negotiation agents in complex negotiation environments through some deep reinforcement learning methods, such as \gls{qmix} and \gls{maddpg}.

\addchap*{Kurzfassung}
\markboth{Kurzfassung}{}

Stellen Sie sich einen Agenten vor, der mit anderen zusammenarbeiten und autonom verhandeln kann, um eine Zustimmung zu erzielen. Diese Agenten könnten großartige Ergebnisse erzielen, beispielsweise die Rentabilität der Fabrik. Diese Art von Agent ist in komplexen und realistischen Umgebungen (z. B. Supply Chain Management) praktisch. In den Experimenten dieser These wird vorgeschlagen, einige kreative Methoden zu verwenden, um lernbare Agenten zu implementieren, um die oben genannten Ziele zu erreichen. Wenn Sie kontinuierlich mit anderen interagieren, wird die Strategie des Agenten verbessert. Die erlernte Strategie ermöglicht es autonomen Agenten, in Echtzeit mit mehreren verschiedenen Arten unbekannter Gegner über komplexe und vielfältige Themen zu verhandeln. In den letzten Jahrzehnten wurde viel Arbeit geleistet, um eine Verhandlungsagentur durch Vereinfachung des Verhandlungsumfelds oder mithilfe von Expertenwissen zu entwickeln. In den letzten Jahren wurden viele interessante End-to-End-Lernmethoden für die Tiefenverstärkung mit mehreren Agenten vorgeschlagen und in komplexen Umgebungen wie Dota 2, Starcraft erfolgreich angewendet. Daher werden natürlich einige Fragen aufgeworfen: Wie werden diese neuen Methoden angewendet und wie steht es mit den Ergebnissen, ohne die Umgebung zu vereinfachen und ohne die Hilfe zusätzlicher Kenntnisse? Die Arbeit dieser These versucht, Trainingsumgebungen einzurichten und End-to-End-Verhandlungsagenten in komplexen Verhandlungsumgebungen durch einige multi-agenten Lernmethoden wie \gls{qmix} und \gls{maddpg} zu implementieren.
